{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f24676-2936-4243-a8d4-13a13a240a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the spaCy library and the displacy module\n",
    "from spacy import displacy  # displacy module is used for drawing dependency trees\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b5fea5-3a10-4953-afb5-e11fd50910c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x25527e94f40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a large language model for English and assign it to the variable 'nlp'\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Call the variable to examine the object\n",
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd9ca7f-21b8-4afd-9c6d-b296c5bbc9cc",
   "metadata": {},
   "source": [
    "MODIFYING SPACY PIPELINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680bf068-ab7b-49f0-9449-8bb67766563a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x25527f779a0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x25528120ee0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x255281540b0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x255281bcec0>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x2552816ea80>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x25528154200>)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline  # examine the components of a pipeline attribute of a Language object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2588971-3e65-4243-a863-f2d395d2b9c6",
   "metadata": {},
   "source": [
    "This returns a spaCy SimpleFrozenList object, which consists of Python tuples with two items:\n",
    "\n",
    "1. component names, e.g. tagger, parser, ner, lemmatizer\n",
    "\n",
    "tagger - signifies whether the word is a noun, adjective, verb, and so on\n",
    "\n",
    "parser - Parser is used to report any syntax error\n",
    "\n",
    "Named Entity Recognition (NER) - It helps to easily identify the key elements in a text, like names of people, places, brands, monetary values, and more.\n",
    "\n",
    "Lemmatizer - It gives the root word as the output.\n",
    "\n",
    "2. the actual components that perform different tasks, e.g. spacy.pipeline.tok2vec.Tok2Vec.\n",
    "\n",
    "Here, tok2vec -> maps Tokens to their numerical representations\n",
    "\n",
    "and attribute_ruler -> applies user-defined rules to Tokens, such as matches for a given linguistic pattern, and adds this information to the Token as an attribute if requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "316ae717-3b44-47a7-a188-e96ddd3f95e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a large language model for English, but exclude named entity recognition ('ner') and syntactic dependency parsing ('parser'). \n",
    "nlp = spacy.load('en_core_web_lg', exclude=['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f642f1c-b43d-42cb-924d-333957580d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x255665fc0a0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x255665fc100>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x255679a5f00>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x255679b3200>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the active components under the Language object 'nlp'\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2acb9e-77be-4f2f-82d6-15da70d136b6",
   "metadata": {},
   "source": [
    "analyze_pipes() method provides an overview of the pipeline components and their interactions. \n",
    "By setting the attribute pretty to True, spaCy prints out a table that lists the components and the annotations they produce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26311585-68a9-40e3-8265-5d916b588fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================= Pipeline Overview =============================\u001b[0m\n",
      "\n",
      "#   Component         Assigns       Requires   Scores      Retokenizes\n",
      "-   ---------------   -----------   --------   ---------   -----------\n",
      "0   tok2vec           doc.tensor                           False      \n",
      "                                                                      \n",
      "1   tagger            token.tag                tag_acc     False      \n",
      "                                                                      \n",
      "2   attribute_ruler                                        False      \n",
      "                                                                      \n",
      "3   lemmatizer        token.lemma              lemma_acc   False      \n",
      "\n",
      "✔ No problems found.\n"
     ]
    }
   ],
   "source": [
    "# Analyse the pipeline and store the analysis under 'pipe_analysis'\n",
    "pipe_analysis = nlp.analyze_pipes(pretty=True)  # analyze_pipes() method returns a Python dictionary, which contains the same information as the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b66e02a7-53aa-45e9-b8bb-4c9d0df0329c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tok2vec': [], 'tagger': [], 'attribute_ruler': [], 'lemmatizer': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the value stored under the key 'problems'\n",
    "pipe_analysis['problems']  # Problem reports are stored in a dictionary under the key problems. We can access the values under the problems key by placing the name of the key in brackets [ ]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c1e8d1-7b18-4b6c-94d2-75ca4086a4df",
   "metadata": {},
   "source": [
    "In this case, the lists are empty, because no problems exist.\n",
    "\n",
    "We use the assert statement with the len() function and the comparison operator == to check that the length of the list is 0.\n",
    "\n",
    "If this assertion is not true, that is, if the length of problem_list is more than 0, which would indicate the presence of a problem, Python will raise an AssertionError and stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c749a65f-f04b-45e4-bf15-5ed7b6c9b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the key/value pairs in the dictionary. Assign the key and value pairs to the variables 'component_name' and 'problem_list'.\n",
    "for component_name, problem_list in pipe_analysis['problems'].items():\n",
    "    \n",
    "    # Use the assert statement to check the list of problems; raise Error if necessary.\n",
    "    assert len(problem_list) == 0, f\"There is a problem with {component_name}: {problem_list}!\"\n",
    "    \n",
    "    # The quotation marks are preceded by the character f. By declaring that this string can be formatted, we can insert variables into the string.\n",
    "    # The variable names inserted into the string are surrounded by curly braces {}. If an error message is raised, these parts of the string will be populated using the values currently stored under the variables component_name and problem_list.\n",
    "    # If no problems are encountered, the loop will pass silently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc680e-e40d-470a-a20f-e5e725a7a728",
   "metadata": {},
   "source": [
    "PROCESSING TEXTS EFFICIENTLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ad635f9-a28c-4110-a31f-055db0ff17d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On October 1, 2009, the Obama administration went ahead with a Bush administration program, increasing nuclear weapons production.',\n",
       " \"The 'Complex Modernization' initiative expanded two existing nuclear sites to produce new bomb parts.\",\n",
       " 'The administration built new plutonium pits at the Los Alamos lab in New Mexico and expanded enriched uranium processing at the Y-12 facility in Oak Ridge, Tennessee.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise the language model again, because we need dependency parsing for the following sections.\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Define a list of example sentences\n",
    "sents = [\"On October 1, 2009, the Obama administration went ahead with a Bush administration program, increasing nuclear weapons production.\", \n",
    "         \"The 'Complex Modernization' initiative expanded two existing nuclear sites to produce new bomb parts.\", \n",
    "         \"The administration built new plutonium pits at the Los Alamos lab in New Mexico and expanded enriched uranium processing at the Y-12 facility in Oak Ridge, Tennessee.\"]\n",
    "\n",
    "# Call the variable to examine output\n",
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223ec81a-6d19-45b2-974f-c78178e85b5a",
   "metadata": {},
   "source": [
    "spaCy Language objects have a specific method, pipe(), for processing texts stored in a Python list.\n",
    "\n",
    "The pipe() method has been optimised for this purpose, processing texts in batches rather than individually, which makes this method faster than processing each list item separately using a for loop.\n",
    "\n",
    "The pipe() method takes a list as input and returns a Python generator named pipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61322634-1ec0-4a45-9a2d-c6c25585cdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Language.pipe at 0x000002552A986EB0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feed the list of sentences to the pipe() method for processing text\n",
    "docs = nlp.pipe(sents)\n",
    "\n",
    "# Call the variable to examine the output\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb55610a-3152-405f-bc34-b7a5c4a252c6",
   "metadata": {},
   "source": [
    "Generators are Python objects that contain other objects. When called, a generator object will yield objects contained within itself.\n",
    "\n",
    "To retrieve all objects in a generator, we must cast the output into another object type, such as a list.\n",
    "List basically collects the generator output for examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b11ac0d4-be41-456c-b76a-9ef90002b88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[On October 1, 2009, the Obama administration went ahead with a Bush administration program, increasing nuclear weapons production.,\n",
       " The 'Complex Modernization' initiative expanded two existing nuclear sites to produce new bomb parts.,\n",
       " The administration built new plutonium pits at the Los Alamos lab in New Mexico and expanded enriched uranium processing at the Y-12 facility in Oak Ridge, Tennessee.]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cast the pipe generator into a list\n",
    "docs = list(docs)\n",
    "\n",
    "# Call the variable to examine the output\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687ee02a-3f75-450b-8e0c-46d92cd41edf",
   "metadata": {},
   "source": [
    "This gives us a list of spaCy Doc objects for further processing."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b615cc9-c34f-495d-9fad-d7ae7dc82614",
   "metadata": {},
   "source": [
    "ADDING CUSTOM ATTRIBUTES TO SPACY OBJECTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6df4205d-a69f-4a1a-803a-0d8b03069702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy allows setting custom attributes to Doc, Span and Token objects.\n",
    "# Import the Doc object from the 'tokens' module in spaCy\n",
    "from spacy.tokens import Doc  #  A Doc is a sequence of Token objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bc7eba2-ed99-471a-a26a-1fc1e10ff289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add two custom attributes to the Doc object, 'age' and 'location' using the set_extension() method.\n",
    "Doc.set_extension(\"age\", default=None)  # custom attributes can be added directly to the Doc object using the set_extension() method\n",
    "Doc.set_extension(\"location\", default=None)\n",
    "\n",
    "# The age and location attributes are now added to the Doc object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b4f9e7d-a4a7-4e50-9587-55cfc649cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary whose values consist of another dictionary with three keys: 'age', 'location' and 'text'.\n",
    "sents_dict = {0: {\"age\": 23, \n",
    "                  \"location\": \"Helsinki\", \n",
    "                  \"text\": \"The Senate Square is by far the most important landmark in Helsinki.\"\n",
    "                 },\n",
    "              1: {\"age\": 35, \n",
    "                  \"location\": \"Tallinn\", \n",
    "                  \"text\": \"The Old Town, for sure.\"\n",
    "                 },\n",
    "              2: {\"age\": 58, \n",
    "                  \"location\": \"Stockholm\", \n",
    "                  \"text\": \"Södermalm is interesting!\"\n",
    "                 }\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55732f5e-8b98-4713-882f-ca6b16d37f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the sents_dict dictionary to process the examples and add the custom attributes to the resulting Doc objects\n",
    "# Set up a placeholder list to hold the processed texts\n",
    "docs = []\n",
    "\n",
    "# Loop over pairs of keys and values in the 'sents_dict' dictionary.\n",
    "# Note that the key/value pairs are available under the items() method.\n",
    "# We refer to these keys and values as 'key' and 'data', respectively.\n",
    "# This means that we used the variable 'data' to refer to the nested\n",
    "# dictionary.\n",
    "for key, data in sents_dict.items():\n",
    "    \n",
    "    # Retrieve the value under the key 'text' from the nested dictionary.\n",
    "    # Feed this text to the language model under 'nlp' and assign the \n",
    "    # result to the variable 'doc'.\n",
    "    doc = nlp(data['text'])\n",
    "    \n",
    "    # Retrieve the values for 'age' and 'location' from the nested dictionary.\n",
    "    # Assign these values into the custom attributes defined for the Doc object.\n",
    "    # Note that custom attributes reside under a pseudo attribute consisting of\n",
    "    # an underscore '_'!  \n",
    "    doc._.age = data['age']\n",
    "    doc._.location = data['location']\n",
    "    \n",
    "    # Append the current Doc object under 'doc' to the list 'docs'\n",
    "    docs.append(doc)\n",
    "    \n",
    "# This provides a list of Doc objects, which is assigned under the variable docs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce2af96-18e3-4da1-844f-777d3f8e453f",
   "metadata": {},
   "source": [
    "Loop over the docs list and print out the Doc and its custom attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4902130b-a79c-4f5f-a7a9-a141424c5dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Senate Square is by far the most important landmark in Helsinki. 23 Helsinki\n",
      "The Old Town, for sure. 35 Tallinn\n",
      "Södermalm is interesting! 58 Stockholm\n"
     ]
    }
   ],
   "source": [
    "# Loop over each Doc object in the list 'docs'\n",
    "for doc in docs: # doc defines what is stored in the new list. We loop over items in the list docs and refer to each item using the variable doc.\n",
    "    \n",
    "    # Print each Doc and the 'age' and 'location' attributes\n",
    "    print(doc, doc._.age, doc._.location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef97dcf-78af-4337-ba90-157a7c773413",
   "metadata": {},
   "source": [
    "The custom attributes can be used to filter the data.\n",
    "\n",
    "One efficient way to filter the data is to use a Python list comprehension.\n",
    "\n",
    "A list comprehension is like a for loop that is declared on the fly using brackets [], which are used to designate lists in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8ef9438-0bc7-4a91-8d54-12cc40209453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[The Senate Square is by far the most important landmark in Helsinki.,\n",
       " The Old Town, for sure.]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a list comprehension to filter the Docs for those whose\n",
    "# 'age' attribute has a value under 40.\n",
    "under_forty = [doc for doc in docs if doc._.get('age') < 40]\n",
    "\n",
    "# Call the variable to examine the output\n",
    "under_forty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b3e73d-d85e-4c42-8ea7-bae31d61ec8e",
   "metadata": {},
   "source": [
    "This returns a list with only two Doc objects that fill the designated criteria, that is, their age attribute has a value below 40."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764cfd69-abfc-4da9-af28-e1624a12ca6c",
   "metadata": {},
   "source": [
    "WRITING PROCESSED TEXTS TO DISK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54636686-3be2-4473-9283-390f4c1205d0",
   "metadata": {},
   "source": [
    "When working with high volumes of texts, we first need to ensure that the pipeline produces the desired results in smaller texts. \n",
    "\n",
    "If it works then we should process all the texts and save the result, because processing large volumes of text takes time and resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75914d06-d51f-4631-99a0-b367054fa0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy provides a special object type named DocBin for storing Doc objects that contain linguistic annotations from spaCy.\n",
    "# Import the DocBin object from the 'tokens' module in spacy\n",
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f06f38b7-57ca-46dc-a586-254bf6a7e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To populate the DocBin object with Docs upon creation, use the docs argument to pass a Python generator or list that contains Doc objects.\n",
    "# In this case, we add the three Docs stored under the variable docs to the DocBin.\n",
    "# Initialize a DocBin object and add Docs from 'docs'\n",
    "docbin = DocBin(docs=docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25457216-8b70-4b72-a5b0-a566298de39a",
   "metadata": {},
   "source": [
    "To add custom attributes to Docs, Spans, or Tokens, set the store_user_data argument to True, e.g. DocBin(docs=docs, store_user_data=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efcd240d-5cb8-4027-b542-bc18128de5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that all three Docs made it into the DocBin by examining the output of its __len__() method.\n",
    "# Get the number of Docs in the DocBin\n",
    "docbin.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a58e7324-dc74-4b33-8eea-29f7995e7d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and feed a string object the language model under 'nlp' and add the resulting Doc to the DocBin object 'docbin'\n",
    "docbin.add(nlp(\"Yet another Doc object.\"))\n",
    "\n",
    "# Verify that the Doc was added; length should be now 4\n",
    "docbin.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6605cc0-fd59-4059-9ea1-97200d4584ae",
   "metadata": {},
   "source": [
    "Write the object to a disk for storage.\n",
    "This can be achieved using the to_disk() method of the DocBin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f68af876-c0b8-488b-b90a-0940f4a2a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DocBin object to disk\n",
    "docbin.to_disk(path='‪‪') # The to_disk() method takes a single argument, path, which defines a path to the file in which the DocBin object should be written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f105d4c0-0c7a-4888-9e3c-bd3a47599a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.tokens._serialize.DocBin at 0x2556aa2d5b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise a new DocBin object and use the 'from_disk' method to load the data from the disk. Assign the result to the variable 'docbin_loaded'.\n",
    "docbin_loaded = DocBin().from_disk(path='C:\\\\Users\\\\PALAK BHATT\\\\Downloads\\\\‪‪')\n",
    "\n",
    "# Call the variable to examine the output\n",
    "docbin_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "125130e8-76b4-447a-aeb2-aabbef2896a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[The Senate Square is by far the most important landmark in Helsinki.,\n",
       " The Old Town, for sure.,\n",
       " Södermalm is interesting!,\n",
       " Yet another Doc object.]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the 'get_docs' method to retrieve Doc objects from the DocBin, passing the vocabulary under 'nlp.vocab' to reconstruct the data.\n",
    "# Cast the resulting generator object into a list for examination.\n",
    "docs_loaded = list(docbin_loaded.get_docs(nlp.vocab))\n",
    "\n",
    "# Call the variable to examine the output\n",
    "docs_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6051e6a7-2ce4-453e-9c22-efb83462c862",
   "metadata": {},
   "source": [
    "SIMPLIFYING OUTPUT FOR NOUN PHRASES AND NAMED ENTITIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1f1996-0306-4f1f-bf5c-cdf6b1821905",
   "metadata": {},
   "source": [
    "Print out the noun chunks in each Doc object contained in the list docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90f02c1b-a218-4183-a507-0f7c0c9768b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Senate Square\n",
      "the most important landmark\n",
      "Helsinki\n",
      "The Old Town\n",
      "Södermalm\n"
     ]
    }
   ],
   "source": [
    "# spaCy provides access to noun phrases via the attribute noun_chunks of a Doc object \n",
    "# Define the first for-loop over the list 'docs'\n",
    "# The variable 'doc' refers to items in the list\n",
    "for doc in docs:\n",
    "    \n",
    "    # Loop over each noun chunk in the Doc object\n",
    "    for noun_chunk in doc.noun_chunks:\n",
    "        \n",
    "        # Print noun chunk\n",
    "        print(noun_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d781ac99-aebc-459c-bb5a-bb86ff8be7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function spacy.pipeline.functions.merge_noun_chunks(doc: spacy.tokens.doc.Doc) -> spacy.tokens.doc.Doc>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For merging noun phrases into a single Token, spaCy provides a function named merge_noun_tokens that can be added to the pipeline stored in a Language object using the add_pipe method\n",
    "# Add component that merges noun phrases into single Tokens\n",
    "nlp.add_pipe('merge_noun_chunks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef50932e-6e07-4390-8dcc-4402cf8625e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x2552a93a940>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x2556b133c40>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x2556aa8acf0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x255a7313a40>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x255a731cdc0>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x2556aa8ad60>),\n",
       " ('merge_noun_chunks',\n",
       "  <function spacy.pipeline.functions.merge_noun_chunks(doc: spacy.tokens.doc.Doc) -> spacy.tokens.doc.Doc>)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that the component was added successfully by examining the pipeline attribute under the Language object nlp\n",
    "# List the pipeline components\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5517a668-1a11-4ff1-8b93-7624f25d715a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[On October 1, 2009, the Obama administration went ahead with a Bush administration program, increasing nuclear weapons production.,\n",
       " The 'Complex Modernization' initiative expanded two existing nuclear sites to produce new bomb parts.,\n",
       " The administration built new plutonium pits at the Los Alamos lab in New Mexico and expanded enriched uranium processing at the Y-12 facility in Oak Ridge, Tennessee.]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the Language object 'nlp' to the list of sentences under 'sents'\n",
    "docs = list(nlp.pipe(sents))\n",
    "\n",
    "# Call the variable to examine the output\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b91fd2c-ea0c-4755-a806-db8f70ba96ae",
   "metadata": {},
   "source": [
    "If we loop over the Tokens in the first Doc object in the list, which can be accessed using brackets at position zero, e.g. [0], we can see that the noun phrases are now merged and tagged using the label NOUN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51256d6d-3570-4b36-874b-1868322ff5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On ADP\n",
      "October PROPN\n",
      "1 NUM\n",
      ", PUNCT\n",
      "2009 NUM\n",
      ", PUNCT\n",
      "the Obama administration NOUN\n",
      "went VERB\n",
      "ahead ADV\n",
      "with ADP\n",
      "a Bush administration program NOUN\n",
      ", PUNCT\n",
      "increasing VERB\n",
      "nuclear weapons production NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "# Loop over Tokens in the first Doc object in the list\n",
    "for token in docs[0]:\n",
    "    \n",
    "    # Print out the Token and its part-of-speech tag\n",
    "    print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56598318-4c3e-4610-aa98-48d4b5f30b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"07695f3ce93a476180fefd8e33356be8-0\" class=\"displacy\" width=\"1975\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">On</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">October</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">1,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">2009,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">the Obama administration</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">went</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">ahead</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">a Bush administration program,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">increasing</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">nuclear weapons production.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-07695f3ce93a476180fefd8e33356be8-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,2.0 925.0,2.0 925.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-07695f3ce93a476180fefd8e33356be8-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-07695f3ce93a476180fefd8e33356be8-0-1\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-07695f3ce93a476180fefd8e33356be8-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M210.0,354.0 L218.0,342.0 202.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-07695f3ce93a476180fefd8e33356be8-0-2\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-07695f3ce93a476180fefd8e33356be8-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M385.0,354.0 L393.0,342.0 377.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-07695f3ce93a476180fefd8e33356be8-0-3\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-07695f3ce93a476180fefd8e33356be8-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,354.0 L573.0,342.0 557.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-07695f3ce93a476180fefd8e33356be8-0-4\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-07695f3ce93a476180fefd8e33356be8-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-07695f3ce93a476180fefd8e33356be8-0-5\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-07695f3ce93a476180fefd8e33356be8-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1085.0,354.0 L1093.0,342.0 1077.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-07695f3ce93a476180fefd8e33356be8-0-6\" stroke-width=\"2px\" d=\"M945,352.0 C945,177.0 1265.0,177.0 1265.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-07695f3ce93a476180fefd8e33356be8-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1265.0,354.0 L1273.0,342.0 1257.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-07695f3ce93a476180fefd8e33356be8-0-7\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-07695f3ce93a476180fefd8e33356be8-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1435.0,354.0 L1443.0,342.0 1427.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-07695f3ce93a476180fefd8e33356be8-0-8\" stroke-width=\"2px\" d=\"M945,352.0 C945,89.5 1620.0,89.5 1620.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-07695f3ce93a476180fefd8e33356be8-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1620.0,354.0 L1628.0,342.0 1612.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-07695f3ce93a476180fefd8e33356be8-0-9\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,264.5 1785.0,264.5 1785.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-07695f3ce93a476180fefd8e33356be8-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1785.0,354.0 L1793.0,342.0 1777.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(docs[0], style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60c4254e-bbe4-4dc8-a45c-c2c8e4442fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "October <class 'spacy.tokens.span.Span'> 1 2\n",
      "the Obama administration <class 'spacy.tokens.span.Span'> 6 7\n",
      "a Bush administration program <class 'spacy.tokens.span.Span'> 10 11\n",
      "nuclear weapons production <class 'spacy.tokens.span.Span'> 13 14\n"
     ]
    }
   ],
   "source": [
    "# spaCy stores noun chunks as Spans, whose start attribute determines the index of the Token where the Span starts, while the end attribute determines where the Span has ended.\n",
    "# Loop over the noun chunks in the first Doc object [0] in the list 'docs'\n",
    "for noun_chunk in docs[0].noun_chunks:\n",
    "    \n",
    "    # Print out noun chunk, its type, the Token where the chunks starts and where it ends\n",
    "    print(noun_chunk, type(noun_chunk), noun_chunk.start, noun_chunk.end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577d5256-2d04-4406-b444-ed83ae5f86b4",
   "metadata": {},
   "source": [
    "MERGING NAMED ENTITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "506fafd9-f8e8-4a32-a45d-84e1e142db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'merge_noun_chunks' function from the pipeline under 'nlp'\n",
    "nlp.remove_pipe('merge_noun_chunks')\n",
    "\n",
    "# Process the original sentences again\n",
    "docs = list(nlp.pipe(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e38f17b-33a8-4fd4-a5fc-5a0559bd7938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x2552a93a940>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x2556b133c40>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x2556aa8acf0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x255a7313a40>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x255a731cdc0>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x2556aa8ad60>)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "304dd292-b154-4241-9a88-00a208612344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'merge_entities' function to the pipeline\n",
    "nlp.add_pipe('merge_entities')\n",
    "\n",
    "# Process the data again\n",
    "docs = list(nlp.pipe(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32bb4f04-d4b9-4e81-a1e7-f8837cdd93d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET\n",
      "administration NOUN\n",
      "built VERB\n",
      "new ADJ\n",
      "plutonium NOUN\n",
      "pits NOUN\n",
      "at ADP\n",
      "the DET\n",
      "Los Alamos PROPN\n",
      "lab NOUN\n",
      "in ADP\n",
      "New Mexico PROPN\n",
      "and CCONJ\n",
      "expanded VERB\n",
      "enriched ADJ\n",
      "uranium NOUN\n",
      "processing NOUN\n",
      "at ADP\n",
      "the Y-12 DET\n",
      "facility NOUN\n",
      "in ADP\n",
      "Oak Ridge PROPN\n",
      ", PUNCT\n",
      "Tennessee PROPN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "# Loop over Tokens in the third Doc object in the list\n",
    "for token in docs[2]:\n",
    "    \n",
    "    # Print out the Token and its part-of-speech tag\n",
    "    print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6126dc8-c036-42f2-a9f6-19e84f181520",
   "metadata": {},
   "source": [
    "Named entities that consist of multiple Tokens, as exemplified by place names such as “Los Alamos” and “New Mexico”, have been merged into single Tokens."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
